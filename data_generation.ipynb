{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate data to train CNN for low-wavenumber gradient prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pavelplotnitskii/Dropbox/Log_extrapolation/scripts/paper_reproduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavelplotnitskii/opt/anaconda3/envs/lw_mac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madagascar not found (called from functions.utils.loaders)! It is OK unless you want to generate data from scratch. Install m8r from ahay.org\n"
     ]
    }
   ],
   "source": [
    "from functions.F_plotting2 import *\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data acquisition setup, which has been used in field data to generate synthetic data with these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/acq_data_parameters_cgg_correct.pkl\n"
     ]
    }
   ],
   "source": [
    "info_file=os.path.join('./data/acq_data_parameters_cgg.pkl')  # 80 sources\n",
    "info_file=os.path.join('./data/acq_data_parameters_cgg_correct.pkl')\n",
    "print(info_file)\n",
    "with open(info_file,'rb') as input:\n",
    "    acq_data=pickle.load(input)\n",
    "log_dict=acq_data['log_dict']\n",
    "log_loc=log_dict['loc']\n",
    "log=log_dict['data']\n",
    "idx = int(log_loc / 25)\n",
    "vh = log_loc * np.ones_like(log)/1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### record data for cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   parameters\n",
    "launch_jobs  =0\n",
    "record_tasks =1\n",
    "run_fwi_flag =0\n",
    "parallel_processing=1\n",
    "flag_plotting=1\n",
    "calculation_spacing=25\n",
    "#################   FWI simulation parameters\n",
    "pars={'data_mode':'cnn_16'}\n",
    "pars.update({'current_data_type':'record_cnn_data'} )\n",
    "#################   velocity model generator parameters\n",
    "pars.update({'dx': calculation_spacing, 'dz': calculation_spacing,\n",
    "    'out_shape':[496,150],  # grid size of generated model\n",
    "    'dsrc':200, # source spacing\n",
    "    'taper_shift':0,    #shift of the water taper\n",
    "    'extend_model_x':False,\n",
    "    'last_source_position':'nx',\n",
    "    'computation_platform':'workstation',\n",
    "    'gen_mode':'generator1',     # 'vlad' or 'oleg' option\n",
    "    'initial_velocity_models_source':'generator',\n",
    "    'root_denise':'',\n",
    "    'data_gen_mode':'pseudo_field'\n",
    "    })\n",
    "################# seismic data filtering parameters\n",
    "corner_frequency=5  # boundary of low frequencies\n",
    "pars.update({'full_band':False})    # high-pass filter for seismic data \n",
    "pars.update({'corner_frequency':corner_frequency} )\n",
    "pars.update({'delete_low_freqs':True} )\n",
    "################# DENISE forward modelling parameters\n",
    "pars.update({\n",
    "        'NNODES': 1,'NPROCX':2,'NPROCY':1,      # small\n",
    "        'ncores':20,'HOURS':24\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up number of data samples to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_folder='./data/gradients/'+pars['data_mode']\n",
    "os.makedirs(res_folder,exist_ok=True)\n",
    "processing_batch_size=10\n",
    "sample_list=list(np.arange(0,2,1))\n",
    "batches=[sample_list[x:x+processing_batch_size]   for x in range(0, len(sample_list), processing_batch_size)]\n",
    "list_of_sbatch_files=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "There are not enough slots available in the system to satisfy the 20\n",
      "slots that were requested by the application:\n",
      "\n",
      "  /bin/denise\n",
      "\n",
      "Either request fewer slots for your application, or make more slots\n",
      "available for use.\n",
      "\n",
      "A \"slot\" is the Open MPI term for an allocatable unit where we can\n",
      "launch a process.  The number of slots available are defined by the\n",
      "environment in which Open MPI processes are run:\n",
      "\n",
      "  1. Hostfile, via \"slots=N\" clauses (N defaults to number of\n",
      "     processor cores if not provided)\n",
      "  2. The --host command line parameter, via a \":N\" suffix on the\n",
      "     hostname (N defaults to 1 if not provided)\n",
      "  3. Resource manager (e.g., SLURM, PBS/Torque, LSF, etc.)\n",
      "  4. If none of a hostfile, the --host command line parameter, or an\n",
      "     RM is present, Open MPI defaults to the number of processor cores\n",
      "\n",
      "In all the above cases, if you want Open MPI to default to the number\n",
      "of hardware threads instead of the number of processor cores, use the\n",
      "--use-hwthread-cpus option.\n",
      "\n",
      "Alternatively, you can use the --oversubscribe option to ignore the\n",
      "number of available slots when deciding the number of processes to\n",
      "launch.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "There are not enough slots available in the system to satisfy the 20\n",
      "slots that were requested by the application:\n",
      "\n",
      "  /bin/denise\n",
      "\n",
      "Either request fewer slots for your application, or make more slots\n",
      "available for use.\n",
      "\n",
      "A \"slot\" is the Open MPI term for an allocatable unit where we can\n",
      "launch a process.  The number of slots available are defined by the\n",
      "environment in which Open MPI processes are run:\n",
      "\n",
      "  1. Hostfile, via \"slots=N\" clauses (N defaults to number of\n",
      "     processor cores if not provided)\n",
      "  2. The --host command line parameter, via a \":N\" suffix on the\n",
      "     hostname (N defaults to 1 if not provided)\n",
      "  3. Resource manager (e.g., SLURM, PBS/Torque, LSF, etc.)\n",
      "  4. If none of a hostfile, the --host command line parameter, or an\n",
      "     RM is present, Open MPI defaults to the number of processor cores\n",
      "\n",
      "In all the above cases, if you want Open MPI to default to the number\n",
      "of hardware threads instead of the number of processor cores, use the\n",
      "--use-hwthread-cpus option.\n",
      "\n",
      "Alternatively, you can use the --oversubscribe option to ignore the\n",
      "number of available slots when deciding the number of processes to\n",
      "launch.\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "list_of_sbatch_files=[]\n",
    "for batch in batches:\n",
    "    for number in batch:\n",
    "        velocity_model_name=number\n",
    "        directory='model_'+str(number)\n",
    "        results_folder = os.path.join(res_folder,directory)\n",
    "        filename_model = os.path.join(results_folder,directory+'.hdf5')\n",
    "        os.makedirs(results_folder,exist_ok=True)\n",
    "        ########################   create folders and files to launch denise\n",
    "        generate_data_for_batch_of_jobs(velocity_generator,denise_fwi,pars['gen_mode'],res_folder,calculation_spacing,pars,number)\n",
    "        denise_fwi(filename_model,results_folder,os.getcwd(),calculation_spacing=calculation_spacing,pars=pars,mode='generate_task_files')\n",
    "        os.system('export GEN='+os.path.join(results_folder,'fld'))\n",
    "        os.system(f\"mpirun -np {pars['ncores']} $DENISE/bin/denise $GEN/seis_forward.inp $GEN/seis_fwi.inp\\n\")\n",
    "        # os.system(f\"mpirun -np {pars['ncores']} $DENISE/bin/denise $GEN/seis_inversion.inp $GEN/seis_fwi.inp\\n\")\n",
    "        ss=1\n",
    "        ########################   create field data processing file\n",
    "        # if pars['computation_platform']=='workstation':\n",
    "        #     str1 = '#!/bin/bash\\n'\n",
    "        #     str1=str1+'export DENISE=./DENISE-Black-Edition\\n'\n",
    "        #     str1=str1+f\"source ~/.bashrc\\n\"\n",
    "        #     str1=str1+f\"conda activate lw\\n\"\n",
    "        #     str1=str1+f\"which python\\n\"\n",
    "        #     str1=str1+'export GEN='+os.path.join(results_folder,'fld')+'\\n'\n",
    "        #     #######\n",
    "        #     str1 = str1 + f\"python {os.path.join(results_folder,'data_generation_script.py')}\\n\"\n",
    "        #     str1=str1+f\"mpirun -np {pars['ncores']} $DENISE/bin/denise $GEN/seis_forward.inp $GEN/seis_fwi.inp\\n\"\n",
    "        #     str1 = str1 + f\"python {os.path.join(results_folder,'field_data_processing_script.py')}\\n\"\n",
    "        #     str1=str1+f\"mpirun -np {pars['ncores']} $DENISE/bin/denise $GEN/seis_inversion.inp $GEN/seis_fwi.inp\\n\"\n",
    "        #     str1 = str1 + f\"python {os.path.join(results_folder,'post_processing_script.py')}\\n\"\n",
    "print('!!!!!!!!halas!!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
