{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic FWI without low-frequencies\n",
    "# Marmousi on full-band data\n",
    "\n",
    "Here, we initialize the elastic full-waveform inversion in a setup identical to the field data experiment and run it on Marmousi II benchmark model.\n",
    "\n",
    "------\n",
    "This notebook reproduces the workflow for generation of synthetic data from from \n",
    "**\"Multi-task learning for low-frequency extrapolation and elastic model building from seismic data\"**\n",
    "\n",
    "by [Ovcharenko Oleg](https://ovcharenkoo.com/), [Vladimir Kazei](https://vkazei.com/), [Tariq Alkhalifah](https://sites.google.com/a/kaust.edu.sa/tariq/home) and [Daniel Peter](https://github.com/danielpeter), KAUST, Saudi Arabia, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha\n",
      "Python: /home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha/env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import importlib\n",
    "import multiprocessing\n",
    "print(os.getcwd())\n",
    "# print(f'Python: {sys.prefix}')\n",
    "# print(os.path.abspath('/home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha/utils/*'))\n",
    "# sys.path.append(os.path.abspath('/home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/codes_server/*'))\n",
    "# sys.path.append(os.path.abspath('/home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha/utils/*'))\n",
    "sys.path.append(os.path.abspath('../for_pasha/utils'))\n",
    "# print(f'sys.path: {sys.path}')\n",
    "import segyio\n",
    "from scipy import signal, ndimage\n",
    "from natsort import natsorted\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "import utils.shared as sd\n",
    "from utils.shared import Survey\n",
    "import utils.loaders as ld\n",
    "import utils.vis as vis\n",
    "\n",
    "# from utils import shared as sd\n",
    "# from utils import loaders as ld\n",
    "# from utils import vis\n",
    "\n",
    "from IPython.display import clear_output\n",
    "# remove the sys.path... line and add pyapi_denise.py to the same directory with the notebook\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import pyapi_denise as api\n",
    "print(f'Python: {sys.prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is to prevent error \"this loop already runnign when doing magical %run <<notebook name>>\"\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# mpl.rcParams['figure.dpi']= 100\n",
    "fontsize = 10\n",
    "params = {\n",
    "    # 'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    # 'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'figure.dpi' : 100,\n",
    "    # 'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 150,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize':fontsize,  # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize':fontsize,\n",
    "    'font.size':fontsize,  # was 10\n",
    "    'legend.fontsize': fontsize,  # was 10\n",
    "    'xtick.labelsize':fontsize,\n",
    "    'ytick.labelsize':fontsize,\n",
    "    # 'text.usetex': True,\n",
    "    # 'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "mpl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_fwi = './pretrained_files/fwi_outputs/out_fwi_marm_nolow/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Denise API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denise_root = '../den/'\n",
    "d = api.Denise(denise_root, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.parser_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work directory\n",
    "Where to output everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.save_folder = root_fwi\n",
    "d.set_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquitision details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = sd.load_obj('./pretrained_files/data/survey.pkl')\n",
    "\n",
    "src = survey.src\n",
    "rec = survey.rec\n",
    "vp = survey.vp\n",
    "dx = survey.dx\n",
    "wb_taper = survey.wb_taper\n",
    "log_idx = survey.log_idx\n",
    "bpw = survey.bpw\n",
    "log_loc = survey.log_loc\n",
    "dDT = survey.dDT\n",
    "dNT = survey.dNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = np.mean(src.x[1:] - src.x[:-1])\n",
    "print('Field data spacing between sources {:.2f} m'.format(dsrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_baseline = vp.copy()\n",
    "print(vp.shape)\n",
    "\n",
    "marm_path = os.path.join(root_fwi, 'start/')\n",
    "os.makedirs(marm_path, exist_ok=True)\n",
    "print(marm_path)\n",
    "if not 'marmousi_II_marine.vp' in os.listdir(marm_path):\n",
    "    # Download Marmousi II model\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.vp -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.vs -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.rho -P {marm_path}')\n",
    "\n",
    "    # Download initial model for FWI\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.vp -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.vs -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.rho -P {marm_path}')\n",
    "\n",
    "def extend(x, ez, ex):\n",
    "    if ex > 0:\n",
    "        x = np.concatenate((x, np.flip(x[:, -ex:], -1)), 1)              # OX\n",
    "    if ez > 0:\n",
    "        x = np.concatenate((x, x.min() * np.ones((ez, x.shape[1]))), 0)  # OZ\n",
    "    return x\n",
    "\n",
    "def get_vp_vs_rho(vp):\n",
    "    # Some model tuning\n",
    "    # Add water\n",
    "    vp = extend(vp, 15, 0)\n",
    "    print(f'Reshape {vp.shape} into {wb_taper.shape}...')\n",
    "    \n",
    "    # Resize end extend\n",
    "    vp = resize(vp, wb_taper.shape, anti_aliasing=True)\n",
    "    vp = np.where(vp <= 1500.0, 1490.0, vp)\n",
    "    vp = extend(vp, 0, 264 + 10 * 8)\n",
    "\n",
    "    # Gardner's relation\n",
    "    # https://www.subsurfwiki.org/wiki/Gardner%27s_equation\n",
    "    # Density, [kg/m3] \n",
    "    rho = 1e3*0.3 * vp.copy()**0.25\n",
    "    rho = np.where(vp < 1.01 * np.min(vp), 1000, rho)\n",
    "    \n",
    "    # Shear velocity, [m/s]\n",
    "    vs = vp.copy() / (3 ** 0.5)\n",
    "    vs = np.where(vp < 1.01 * np.min(vp), 0, vs)\n",
    "\n",
    "    return vp, vs, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-scale to field survey dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_marm = ld.load_bin(f'{marm_path}marmousi_II_marine.vp', (500, 174))[:, 100:]\n",
    "print(vp_marm.min(), vp_marm.max())\n",
    "\n",
    "# This is what was used in generation of training data\n",
    "box_min = 1490.\n",
    "box_max = 4000. \n",
    "\n",
    "vmin_marm = vp_marm.min()\n",
    "vp_marm -= vmin_marm\n",
    "\n",
    "vmax_marm = vp_marm.max()\n",
    "vp_marm /= vmax_marm\n",
    "vp_marm = box_min  + vp_marm * (box_max - box_min)\n",
    "print(vp_marm.min(), vp_marm.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make vs, rho from vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp, vs, rho = get_vp_vs_rho(vp_marm)\n",
    "vis.plot_acquisition(vp, dx, src, rec, title='Vp')\n",
    "model = api.Model(vp, vs, rho, dx)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good initial model\n",
    "This one is available together with the true model in DENISE-Black-Edition repository. We do not use it in inversion but rather have it as a reference.\n",
    "\n",
    "**NOT USED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_marm_linear = ld.load_bin(f'{marm_path}marmousi_II_start_1D.vp', (500, 174))[:, 100:]\n",
    "vp_marm_linear -= vmin_marm\n",
    "vp_marm_linear /= vmax_marm\n",
    "vp_marm_linear = box_min  + vp_marm_linear * (box_max - box_min)\n",
    "\n",
    "vp_linear, vs_linear, rho_linear = get_vp_vs_rho(vp_marm_linear)\n",
    "vis.plot_acquisition(vp_linear, dx, src, rec, title='Vp')\n",
    "model_linear = api.Model(vp_linear, vs_linear, rho_linear, dx)\n",
    "\n",
    "log_linear = vp_linear[:, log_idx]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom wavelet\n",
    "wls = bpw[:, ::2]\n",
    "src.wavelets = wls[:, :dNT]\n",
    "\n",
    "vis.plot_acquisition(vp, dx, src, rec, title='Vp')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well-log location\n",
    "log_loc = 10500\n",
    "log = model.vp[:, log_idx]\n",
    "\n",
    "log_dict = {'data':log/2, 'loc': log_loc}\n",
    "vis.plot_acquisition(vp[:, :500], dx, src, rec, log=log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_taper = model.vp < 1.01 * model.vp.min()\n",
    "print(wb_taper.shape, model.vp.shape, vp_linear.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_new = np.zeros_like(model.vp)\n",
    "vps=[]\n",
    "for i in range(wb_taper.shape[-1]):\n",
    "    wb = wb_taper.shape[0] - np.argmax(wb_taper[:,i]) + 2\n",
    "    fun = box_min * np.ones_like(vp_new[:, 0:1])\n",
    "    fun[wb:, :] = 420 + fun[wb:, :] + 12 * np.expand_dims(np.arange(len(fun[wb:, 0])), 1)\n",
    "    fun = fun[::-1, :]\n",
    "    vps.append(fun)\n",
    "vp_new = np.concatenate(vps, -1)\n",
    "\n",
    "# Assume known water bottom and shallow sediments\n",
    "# This assumption is not used in experiment with predicted data\n",
    "ids, ide = -33, None\n",
    "vp_new[ids:ide, :] = vp_linear[ids:ide, :]\n",
    "\n",
    "print(vp_new.shape)\n",
    "log_new = vp_new[-len(log):, log_idx]\n",
    "\n",
    "fig, ax = plt.subplots(1,1); \n",
    "ax_depth = np.arange(len(log)) * dx / 1000\n",
    "ax.plot(ax_depth, log[::-1] / 1000, 'r', label='Well')\n",
    "ax.plot(ax_depth, log_linear[::-1] / 1000, 'k--', label='Perfect init')\n",
    "ax.plot(ax_depth, log_new[::-1] / 1000, 'b', label='Regular init')\n",
    "ax.set_ylabel('Velocity, km/s')\n",
    "ax.set_xlabel('Depth, km')\n",
    "ax.grid(True)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create initial **from regular initial model** (blue in the chart above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shear velocity, [m/s]\n",
    "vs_new = vp_new.copy() / (3 ** 0.5)\n",
    "vs_new = np.where(vp_new < 1.01 * np.min(vp_new), 0, vs_new)\n",
    "\n",
    "# density, [kg/m3] \n",
    "rho_new = 1e3*0.3 * vp_new.copy()**0.25\n",
    "rho_new = np.where(vp_new < 1.01 * np.min(vp_new), 1000, rho_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src, end='\\n\\n------------\\n')\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate true waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some runtime parameters which are different from defaults. Check defaults by runnning `help()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic modeling\n",
    "d.verbose = 1\n",
    "d.PHYSICS = 1\n",
    "d.SEISMO = 2\n",
    "d.DT = dDT\n",
    "d.NT = dNT\n",
    "d.TIME = dDT * d.NT\n",
    "#\n",
    "d.FC_SPIKE_2 = 10\n",
    "d.REC_INCR_X = dsrc\n",
    "d.N_STREAMER = len(rec)\n",
    "\n",
    "d.TESTSHOT_START = 1\n",
    "d.TESTSHOT_END = len(src)\n",
    "d.TESTSHOT_INCR = 10\n",
    "\n",
    "d.QUELLTYPB = 4\n",
    "d.QUELLART = 3  \n",
    "\n",
    "d.WRITE_STF = 0\n",
    "\n",
    "# Acoustic case \n",
    "# d.PHYSICS = 2\n",
    "# src.wavelets = -wls[:, :limit_nt]\n",
    "\n",
    "print(d.DT, d.NT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run forward modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Found {multiprocessing.cpu_count()} cores in your machine. Manually set \"num_parallel_shots\" below')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.NPROCX = 1\n",
    "d.NPROCY = 1\n",
    "\n",
    "# Edit the line below to match your machine specs\n",
    "num_parallel_shots = 4# 40\n",
    "\n",
    "par_forward = {'run_command': f'mpirun -np {num_parallel_shots}', 'disable': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.listdir(d._root_su):\n",
    "    print(f'Create {d.save_folder} and run forward modeling...')\n",
    "    d.forward(model, src, rec, **par_forward)\n",
    "else:\n",
    "    print(f'Synthetic seismic data already exists in {d._root_su}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d.verbose = 0    # don't show redundant print outs\n",
    "\n",
    "if d.DT is None:\n",
    "    d.DT = 0.002\n",
    "shots = d.get_shots(keys=['_p.'])\n",
    "# shots = [ld.bandpass(s, fs=1./(d.DT * d.NDT), **par_bp) for s in d.get_shots(keys=['_p'])]\n",
    "\n",
    "par_shot = {'vmin': -0.05, 'vmax': 0.05}\n",
    "if shots:\n",
    "    print(f'Read {len(shots)} shots {shots[0].shape} into list')\n",
    "    for i in [int(np.floor(x)) for x in np.linspace(0, len(shots)-1, 2)]:\n",
    "        try:\n",
    "            shot_s = ld.divmax(shots[i])\n",
    "            vis.plot_shot(shot_s, pclip=0.1)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to fetch data for i={i}. {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelets_s = []\n",
    "for i, shot in enumerate(shots):\n",
    "    no, nt = 1, 500\n",
    "    wavelets_s.append(shot[:no, :nt].copy())\n",
    "print(f'Total sources: {len(wavelets_s)}')\n",
    "wavelets_s = np.concatenate(wavelets_s, 0)\n",
    "print('Syn wavelets:\\t{}\\t{:.2f}\\t{:.2f}'.format(wavelets_s.shape, wavelets_s.min(), wavelets_s.max()))\n",
    "vis.plot_wiggles(wavelets_s, n=10, colors=['k'], legend=['Syn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_taper = np.where(model.vp < 1.01 * model.vp.min(), 1, 0)\n",
    "nx0 = 500\n",
    "nz0 = model.vp.shape[0]\n",
    "limits_vp = {'vmin': model.vp.min() / 1000, 'vmax': model.vp.max() / 1000}\n",
    "limits_vs = {'vmin': model.vs.min() / 1000, 'vmax': model.vs.max() / 1000}\n",
    "limits_rho = {'vmin': model.rho.min() / 1000, 'vmax': model.rho.max() / 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi']= 300\n",
    "vis.plot_log_model(vp_new, dx, nx0, nz0, src, **limits_vp)\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop predicted model\n",
    "Large part of the model (beyond last source) was only to get full-offset seismic data. When running inversion it is not needed so we cut it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcut = 672\n",
    "wb_taper = wb_taper[:, :xcut]\n",
    "model_init = api.Model(vp_new[:, :xcut], vs_new[:, :xcut], rho_new[:, :xcut], dx)\n",
    "print(model_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-waveform inversion\n",
    "Invert for elastic properties `vp`, `vs` and `rho`, given `x` and `y` velocity components of wavefield "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial velocity model\n",
    "Smooth background model with true water bottom and shallow sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plot_model(np.concatenate((model_init.vp, model_init.vs, model_init.rho), 1))\n",
    "# plot_logs(model_log, model_init, log_idx)\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "fig, ax = plt.subplots(1,1); \n",
    "# ax_depth = np.arange(len(wlog)) * dx / 1000\n",
    "ax_depth = np.arange(len(log_linear)) * dx / 1000\n",
    "ax.plot(ax_depth, log[::-1] / 1000, 'k', label='Well')\n",
    "log_bad = model_init.vp[-len(log):, log_idx]\n",
    "ax.plot(ax_depth, log_bad[::-1] / 1000, 'r', label='Linear initial')\n",
    "ax.plot(ax_depth, log_linear[::-1] / 1000, 'k--', label='Ideal initial')\n",
    "ax.set_ylabel('Velocity, km/s')\n",
    "ax.set_xlabel('Depth, km')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "mpl.rcParams['figure.dpi']= 100\n",
    "print(len(log), model_init.vp.shape, len(model_init.vp[:len(log)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_logs(model, model_init, log_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stages of inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_stages_fwi = {'inv_vs_iter': 0,\n",
    "                 'inv_rho_iter': 0,\n",
    "                 'normalize': 2,\n",
    "                 'spatfilter': 4,\n",
    "                 'order': 6,\n",
    "                 }\n",
    "\n",
    "d.fwi_stages = []\n",
    "d.add_fwi_stage(fc_low=5, fc_high=8, \n",
    "                wd_damp=2,\n",
    "                wd_damp1=2,\n",
    "                **par_stages_fwi)\n",
    "print(f'Stage {i+1}:\\n\\t{d.fwi_stages[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.SWS_TAPER_GRAD_HOR = 1\n",
    "d.GRADT1, d.GRADT2 = 25, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient tapering\n",
    "# d.SWS_TAPER_GRAD_VERT = 0\n",
    "# d.SWS_TAPER_CIRCULAR_PER_SHOT = 0   # enable grad tapering around sources\n",
    "\n",
    "# Box conditions for FWI\n",
    "d.VPUPPERLIM = 4000.\n",
    "d.VPLOWERLIM = 1490.\n",
    "d.VSUPPERLIM = 2500.\n",
    "d.VSLOWERLIM = 0.\n",
    "d.RHOUPPERLIM = 2500.\n",
    "d.RHOLOWERLIM = 1000.\n",
    "\n",
    "d.SWS_TAPER_FILE = 1\n",
    "\n",
    "taper = np.zeros_like(model_init.vp)\n",
    "print(taper.shape,wb_taper.shape)\n",
    "shift = 4\n",
    "taper[shift:, :] = wb_taper[:-shift,:] # water mask\n",
    "\n",
    "if d.SWS_TAPER_FILE:\n",
    "    os.makedirs(d._root_tapers, exist_ok=True)\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper.bin'))\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper_u.bin'))\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper_rho.bin'))\n",
    "    vis.plot_acquisition(taper, dx, src, rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Target data: {d.DATA_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.WRITE_STF = 0\n",
    "d.NPROCX = 8\n",
    "d.NPROCY = 2\n",
    "d.verbose = 1\n",
    "par_fwi_runtime = {'run_command': 'mpirun -np 32', 'disable': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.fwi(model_init, src, rec, **par_fwi_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize FWI outputs\n",
    "It will not hurt to make sure that paths and model dims are up to date. This is necessary when you only want to plot pictures, without running modeling or FWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_model(model_init)\n",
    "d.set_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted model from linear initial\n",
    "The code ouputs inverted models for every elastic property at every FWI stage. Change `vp` to `vs` or `rho` to explore respective outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi']= 300\n",
    "d.verbose = 2\n",
    "\n",
    "models, fnames = d.get_fwi_models(['vp', 'stage'], return_filenames=True)\n",
    "for m, f in zip(models, fnames):\n",
    "    vis.plot_log_model(m, dx, nx0, nz0, src, **limits_vp)\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_log_model(m, dx, nx0, nz0, dpi=300, **limits_vp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-logs\n",
    "Plot logs in true model (dashed) and inverted models (solid) for every inversion stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inverted models from all stages\n",
    "vvr = {'vp': None, 'vs': None, 'rho': None}\n",
    "for k in vvr.keys():\n",
    "    vvr[k], fnames = d.get_fwi_models([k + '_stage'], return_filenames=True)\n",
    "\n",
    "for i in range(len(vvr['vp'])):\n",
    "    vis.plot_logs(model, api.Model(vvr['vp'][i], vvr['vs'][i], vvr['rho'][i], dx), log_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d.verbose = 0\n",
    "# grads, fnames = d.get_fwi_gradients(return_filenames=True)\n",
    "# for g, f in zip(grads, fnames):\n",
    "#     plot_model(g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d.help()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
