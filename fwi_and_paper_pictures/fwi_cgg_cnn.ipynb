{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FWI on field data (CGG Broadseis)\n",
    "\n",
    "by Oleg Ovcharenko\n",
    "\n",
    "oleg.ovcharenko@kaust.edu.sa\n",
    "\n",
    "KAUST, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha/env\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shared'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a7464944ef68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnatsort\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnatsorted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshared\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shared'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#api._cmd('conda activate torch2')\n",
    "print(f'Python: {sys.prefix}')\n",
    "import copy\n",
    "from glob import glob\n",
    "# import glob\n",
    "import numpy as np\n",
    "import importlib\n",
    "import multiprocessing\n",
    "\n",
    "import segyio\n",
    "from scipy import signal, ndimage\n",
    "from natsort import natsorted\n",
    "from skimage.transform import rescale, resize\n",
    "import shared as sd\n",
    "import loaders as ld\n",
    "import vis\n",
    "from IPython.display import clear_output\n",
    "# append path with actual source files to sys.path\n",
    "sys.path.append(os.path.abspath('../codes_server'))\n",
    "from F_utils import *\n",
    "from F_fwi import *\n",
    "import pyapi_denise as api\n",
    "api._cmd('source /home/plotnips/Madagascar/share/madagascar/etc/env.sh')\n",
    "api._cmd('source ~/.bashrc')\n",
    "# create_sbatch_file_for_fwi_folder('./for_pasha/out_for_pasha/fwi_full_spectrum_vanilla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is to prevent error \"this loop already runnign when doing magical %run <<notebook name>>\"\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# mpl.rcParams['figure.dpi']= 100\n",
    "fontsize = 10\n",
    "params = {\n",
    "    # 'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    # 'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'figure.dpi' : 100,\n",
    "    # 'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 150,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize':fontsize,  # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize':fontsize,\n",
    "    'font.size':fontsize,  # was 10\n",
    "    'legend.fontsize': fontsize,  # was 10\n",
    "    'xtick.labelsize':fontsize,\n",
    "    'ytick.labelsize':fontsize,\n",
    "    # 'text.usetex': True,\n",
    "    # 'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "mpl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_fwi = './out_for_pasha/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Denise API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denise_root = '../'\n",
    "d = api.Denise(denise_root, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work directory\n",
    "Where to output everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.save_folder = root_fwi\n",
    "d.set_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquitision details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_id_min = 60\n",
    "n_selected_shots = 80\n",
    "njump_src = 8\n",
    "shot_id_max = shot_id_min + (n_selected_shots-1) * njump_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./fwi_shared_check.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Field data spacing between sources {:.2f} m'.format(np.mean(src_.x[1:] - src_.x[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_baseline = vp.copy()\n",
    "print(vp.shape)\n",
    "\n",
    "marm_path = os.path.join(root_fwi, 'start/')\n",
    "os.makedirs(marm_path, exist_ok=True)\n",
    "print(marm_path)\n",
    "if not 'marmousi_II_marine.vp' in os.listdir(marm_path):\n",
    "    # Download Marmousi II model\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.vp -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.vs -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_marine.rho -P {marm_path}')\n",
    "\n",
    "    # Download initial model for FWI\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.vp -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.vs -P {marm_path}')\n",
    "    os.system(f'wget https://github.com/daniel-koehn/DENISE-Benchmark/raw/master/Marmousi-II/start/marmousi_II_start_1D.rho -P {marm_path}')\n",
    "    \n",
    "def get_vp_vs_rho(vp):\n",
    "    vp = extend(vp, 15, 0)\n",
    "\n",
    "    print(f'Reshape {vp.shape} into {wb_taper.shape}...')\n",
    "\n",
    "    vp = resize(vp, wb_taper.shape, anti_aliasing=True)\n",
    "    vp = np.where(vp <= 1500.0, 1490.0, vp)\n",
    "    vp = extend(vp, 0, 264 + 10 * 8)\n",
    "\n",
    "    # shear velocity, [m/s]\n",
    "    vs = vp.copy() / (3 ** 0.5)\n",
    "    vs = np.where(vp < 1.01 * np.min(vp), 0, vs)\n",
    "\n",
    "    # density, [kg/m3] \n",
    "    rho = 1e3*0.3 * vp.copy()**0.25\n",
    "    rho = np.where(vp < 1.01 * np.min(vp), 1000, rho)\n",
    "    return vp, vs, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the model so it accommodates full streamer length for the last shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = extend(model.vp, 0, 264 + 10 * 8)\n",
    "vp_cgg_tomo=vp_cgg\n",
    "vp_long = vp.copy()\n",
    "vp_cgg_tomo_long = extend(vp_cgg_tomo, 0, 264 + 10 * 8)\n",
    "print(vp_long.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet scaler to match field and synthetic\n",
    "wavefield_amp_ratio = 77.08343437940496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom wavelet\n",
    "wls = bpw[:, ::2]\n",
    "src.wavelets = wavefield_amp_ratio * wls[:, :limit_nt]\n",
    "\n",
    "vis.plot_acquisition(vp, dx, src, rec, title='Vp',**{'vmax': 4.5, 'vmin': 1.5})\n",
    "vis.plot_acquisition(vp_cgg_tomo_long, dx, src, rec, title='Vp',**{'vmax': 4.5, 'vmin': 1.5})\n",
    "print(vp.shape)\n",
    "print(vp_cgg_tomo_long.shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_taper = np.where(vp_cgg_tomo_long < 1.01 * vp_cgg_tomo_long.min(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = model.vp[:, log_idx]\n",
    "log = model.vp[-len(wlog):, log_idx]\n",
    "# model_log = copy.deepcopy(model)\n",
    "\n",
    "log_dict = {'data':wlog, 'loc': log_loc}\n",
    "vis.plot_acquisition(vp[:, :500], dx, src, rec, log=log_dict)\n",
    "vis.savefig('vinit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wb_taper.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new initial (orange line). This is to see whether knowledge about exact waterbottom will improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vp = np.zeros_like(model.vp)\n",
    "vps=[]\n",
    "for i in range(wb_taper.shape[-1]):\n",
    "    wb = wb_taper.shape[0] - np.argmax(wb_taper[:,i]) + 2\n",
    "    fun = vmin * np.ones_like(new_vp[:, 0:1])\n",
    "    fun[wb:, :] = 690 + fun[wb:, :] + 6 * np.expand_dims(np.arange(len(fun[wb:, 0])), 1)\n",
    "    fun = fun[::-1, :]\n",
    "    vps.append(fun)\n",
    "new_vp = np.concatenate(vps, -1)\n",
    "new_vp = gaussian_filter(new_vp.copy(), **sigma_truncate)\n",
    "\n",
    "print(new_vp.shape)\n",
    "print(f'Well-log from {log_loc} maps into ix: {log_idx}')\n",
    "plt.figure(); plt.plot(wlog, 'k--'); plt.plot(log[-len(wlog):]); plt.plot(new_vp[-len(wlog):, log_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set new model as initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = vp_cgg_tomo_long.copy()\n",
    "# vp = new_vp.copy()\n",
    "vs = vp.copy() / (3 ** 0.5)\n",
    "rho = 1e3*0.3 * vp.copy()**0.25\n",
    "\n",
    "vp = np.where(wb_taper, np.min(vp_cgg), vp)\n",
    "vs = np.where(wb_taper, 0, vs)\n",
    "rho = np.where(wb_taper, 1000, rho)\n",
    "\n",
    "# log = vplog.copy()\n",
    "model = api.Model(vp, vs, rho, dx)\n",
    "print(src, end='\\n\\n------------\\n')\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate true waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some runtime parameters which are different from defaults. Check defaults by runnning `help()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic modeling\n",
    "d.verbose = 1\n",
    "d.PHYSICS = 1\n",
    "d.DT = dDT\n",
    "d.NT = data_p.shape[-1]\n",
    "d.TIME = dDT * d.NT\n",
    "#\n",
    "d.FC_SPIKE_2 = 10\n",
    "# DSCRC=5000;     \n",
    "# dsrc=DSCRC\n",
    "d.REC_INCR_X = dsrc\n",
    "d.N_STREAMER = len(rec)\n",
    "d.TESTSHOT_START = 1\n",
    "d.TESTSHOT_END = len(src)\n",
    "d.TESTSHOT_INCR = 10\n",
    "d.QUELLTYPB = 4\n",
    "d.QUELLART = 3  \n",
    "d.WRITE_STF = 0\n",
    "d.SEISMO = 2\n",
    "\n",
    "# d.TESTSHOT_START = np.round(0.1 * len(src))\n",
    "# d.TESTSHOT_END = np.round(0.9 * len(src))\n",
    "# d.TESTSHOT_INCR = 5\n",
    "print(d.DT, d.NT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run forward modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.NPROCX = 1\n",
    "d.NPROCY = 1\n",
    "par_forward = {'run_command': 'mpirun -np 30', 'disable': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.forward(model, src, rec, **par_forward)\n",
    "# d.save_folder = root_fwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d.verbose = 0    # don't show redundant print outs\n",
    "\n",
    "if d.DT is None:\n",
    "    d.DT = 0.002\n",
    "print(d.DATA_DIR)\n",
    "shots = d.get_shots(keys=['_p.'])\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 100\n",
    "par_shot = {'vmin': -0.05, 'vmax': 0.05}\n",
    "if shots:\n",
    "    print(f'Read {len(shots)} shots {shots[0].shape} into list')\n",
    "    for i in [int(np.floor(x)) for x in np.linspace(0, len(shots)-1, 5)]:\n",
    "        try:\n",
    "            shot_s = shots[i]\n",
    "            shot_f = data_p[i, :, ::d.NDT]\n",
    "            vis.plot_compare_stripes(shot_s, shot_f, pclip=0.0125, colorbar=False, dt=d.DT, dx=dx)\n",
    "        except:\n",
    "            print(f'Failed to fetch data for i={i}')\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavefield_amp_ratio\n",
    "print(np.max(np.abs(shot_f)) / np.max(np.abs(shot_s)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare syn and field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelets_s = []\n",
    "wavelets_f = []\n",
    "print(data_p.shape)\n",
    "print(len(shots))\n",
    "for i, shot in enumerate(shots):\n",
    "    no, nt = 1, 500\n",
    "    wavelets_s.append(shot[:no, :nt].copy())\n",
    "    wavelets_f.append(data_p[i, :no, :nt:d.NDT].copy())\n",
    "print(f'Total sources: {len(wavelets_f)}')\n",
    "wavelets_s = np.concatenate(wavelets_s, 0)\n",
    "wavelets_f = np.concatenate(wavelets_f, 0)\n",
    "\n",
    "# !!! DO THIS IN FIELD DATA APPLICATION !!!\n",
    "# THIS MAKES SYNTHETIC AND FIELD COMPARABLE\n",
    "# OTHERWISE THERE IS INSANE AMPLITUDE MISMATCH\n",
    "# wavelets_f /= np.max(wavelets_f)\n",
    "# wavelets_f *= wavelets_s.max()\n",
    "\n",
    "print('Syn wavelets:\\t{}\\t{:.2f}\\t{:.2f}'.format(wavelets_s.shape, wavelets_s.min(), wavelets_s.max()))\n",
    "print('Field wavelets:\\t{}\\t{:.2f}\\t{:.2f}'.format(wavelets_f.shape, wavelets_f.min(), wavelets_f.max()))\n",
    "\n",
    "vis.plot_wiggles([wavelets_f, wavelets_s], n=10, colors=['r', 'b'], legend=['Field', 'Syn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shots:\n",
    "    tvec = np.arange(nt) * d.DT\n",
    "    plt.figure(figsize=(6,3)); \n",
    "    trace_idx = 0\n",
    "    plt.plot(tvec, wavelets_f[trace_idx,:], 'r', lw=2, label='Field')\n",
    "    plt.plot(tvec, wavelets_s[trace_idx,:], 'b', lw=2, label='Syn')\n",
    "    # plt.plot(tvec, _dplotted[0][0], 'r', lw=2, label='Field')\n",
    "    # plt.plot(tvec, _dplotted[1][0], 'b', lw=2, label='Syn')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time, sec')\n",
    "    vis.savefig('wavelet_syn_field.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACE FIELD DATA BY MARM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_p = np.concatenate([np.expand_dims(s, 0) for s in shots], 0)\n",
    "# print(data_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_mutter = {'k': 7, 'b': 100, 'r': 30}\n",
    "\n",
    "new_data_p = []\n",
    "for idat in range(data_p.shape[0]):\n",
    "    new_data_p.append(np.expand_dims(ld.mutter(data_p[idat, ...], **par_mutter), 0))\n",
    "new_data_p = np.concatenate(new_data_p)\n",
    "data_p=new_data_p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_shot(new_data_p[0,...], pclip=0.0125)\n",
    "vis.plot_shot(new_data_p[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par_mutter = {'k': 7, 'b': 100, 'r': 30}\n",
    "# vis.plot_shot(ld.mutter(data_p[0,...], **par_mutter), pclip=0.0125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p_backup = data_p.copy()\n",
    "print(data_p_backup.shape, d.DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric spreading correction (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = np.repeat(np.repeat(np.arange(1, data_p.shape[-1]+1)[np.newaxis, ...] * d.DT, data_p.shape[1], 0)[np.newaxis, ...], data_p.shape[0], 0) ** 0.5\n",
    "\n",
    "# Overwrite by ones, so it is not used\n",
    "geom = np.ones_like(geom)\n",
    "data_p = data_p_backup * geom\n",
    "# data_p = data_p_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_p = np.concatenate([np.expand_dims(s, 0) for s in shots], 0)\n",
    "print(data_p.shape, data_p.min(), data_p.max())\n",
    "dref = np.mean(data_p, 0)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "vis.plot_shot(dref, title='Field data', pclip=0.25, colorbar=True, ax=ax[0])\n",
    "vis.plot_spectrum(dref, dt=0.002, fmax=10, title='Spectrum', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save field data to a new folder in /su/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_su_from_to(path_from, path_to):\n",
    "    \"\"\" Copy files matching *.su.* from one folder to another folder\"\"\"\n",
    "    os.makedirs(path_to, exist_ok=True)\n",
    "    su_files = glob(path_from + '/*.su.*')\n",
    "    su_files = [f for f in su_files if '.it' not in f]\n",
    "    print(f'Found {len(su_files)} *.su.* files in {path_from}')\n",
    "\n",
    "    commands = []\n",
    "    print(f'Copy files from {path_from} to {path_to}')\n",
    "    for f in su_files:\n",
    "        commands.append(f'cp {f} {path_to}')\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(os.system, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "root_su_field = os.path.join(d._root_su, 'field/'); \n",
    "print(d._root_su)\n",
    "print(root_su_field)\n",
    "copy_su_from_to(d._root_su, root_su_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fnames_pattern(pattern):    \n",
    "    fnames = natsorted(glob(pattern))\n",
    "    fnames = [f for f in fnames if '.it' not in f]\n",
    "    print(f'{len(fnames)} files found in {pattern}')\n",
    "    return fnames\n",
    "fnames = get_fnames_pattern(root_su_field + '*.su.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write field data into created .su files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_p.shape, geom.shape)\n",
    "geom_slice = geom[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(fnames):\n",
    "    with segyio.su.open(f, \"r+\", endian='little', ignore_geometry=True) as dst:\n",
    "        tmp = data_p[i, :, ::d.NDT] / geom_slice[..., ::d.NDT]\n",
    "        dst.trace = tmp\n",
    "        print(f, dst.tracecount, tmp.shape, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy field data to folder with FWI for CNN and apply high-pass filter above 5 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_taper = np.where(model.vp < 1.01 * model.vp.min(), 1, 0)\n",
    "vis.plot_model(wb_taper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx0 = 500\n",
    "limits_vp = {'vmin': model.vp.min() / 1000, 'vmax': model.vp.max() / 1000}\n",
    "vis.plot_log_model(model.vp, dx, nx0, nz0, src, log=wlog, log_location=log_location, **limits_vp)\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstraction over initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = copy.copy(model)\n",
    "print(model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wlog.shape, vp.shape)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(wlog)\n",
    "ax.plot(vp[-len(wlog):, log_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-waveform inversion\n",
    "Invert for elastic properties `vp`, `vs` and `rho`, given `x` and `y` velocity components of wavefield "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial velocity model\n",
    "Smooth background model with true water bottom and shallow sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plot_model(np.concatenate((model_init.vp, model_init.vs, model_init.rho), 1))\n",
    "# plot_logs(model_log, model_init, log_idx)\n",
    "\n",
    "fig, ax = plt.subplots(1,1); \n",
    "ax_depth = np.arange(len(wlog)) * dx / 1000\n",
    "# ax_depth = np.arange(len(log_linear)) * dx / 1000\n",
    "ax.plot(ax_depth, wlog[::-1] / 1000, 'k', label='Well')\n",
    "ax.plot(ax_depth, log[::-1] / 1000, 'k--', label='Ideal initial')\n",
    "\n",
    "# log_pred = model_init.vp[-len(wlog):, log_idx]\n",
    "\n",
    "log_pred = model_init.vp[-len(log):, log_idx]\n",
    "ax.plot(ax_depth, log_pred[::-1] / 1000, 'r', label='Predicted initial')\n",
    "\n",
    "nwater = 33#33\n",
    "dummy = np.zeros_like(model.vp)\n",
    "dummy[-nwater:, :] = 1.\n",
    "log_taper = np.min(log_pred) + dummy[:, log_idx] * (np.max(log_pred) - np.min(log_pred))\n",
    "log_taper = np.min(log_pred) + wb_taper[-len(wlog):, log_idx] * (np.max(log_pred) - np.min(log_pred))\n",
    "# ax.plot(ax_depth, log_taper[::-1]  / 1000, 'b', label='Taper')\n",
    "# \n",
    "# ax.plot(ax_depth, log_linear[::-1] / 1000, 'k--', label='Linear')\n",
    "ax.set_ylabel('Velocity, km/s')\n",
    "ax.set_xlabel('Depth, km')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "print(len(wlog), model_init.vp.shape, len(model_init.vp[:len(wlog)]))\n",
    "plot_logs(model_log, model_init, log_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN inversion. Stages of inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from F_utils import *\n",
    "from F_fwi import *\n",
    "denise_root = '../'\n",
    "results_path='./out_for_pasha/cnn'\n",
    "denise_shaheen_root='/lustre/project/k1404/pavel/DENISE-Black-Edition'\n",
    "os.system(f\"rm -r {results_path}\")\n",
    "ITERMAX=55\n",
    "\n",
    "d = api.Denise(denise_root, verbose=1)\n",
    "d.save_folder=os.path.join(results_path,'fld','');      print(d.save_folder)\n",
    "d.set_paths(makedirs=True)\n",
    "\n",
    "d.PHYSICS=1\n",
    "d.INV_MOD_OUT=1\n",
    "d.REC_INCR_X = dsrc\n",
    "d.N_STREAMER = len(rec)\n",
    "d.TESTSHOT_START = 1\n",
    "d.TESTSHOT_END = len(src)\n",
    "d.TESTSHOT_INCR = 10\n",
    "d.QUELLTYPB = 4\n",
    "d.QUELLART = 3  \n",
    "d.WRITE_STF = 0\n",
    "d.SEISMO = 2\n",
    "\n",
    "d.SWS_TAPER_GRAD_HOR = 1\n",
    "d.GRADT1, d.GRADT2 = 25, 30\n",
    "# import loaders as ld\n",
    "d.VPLOWERLIM = np.min(model_init.vp)\n",
    "d.VSLOWERLIM = np.min(model_init.vs)\n",
    "d.RHOLOWERLIM = np.min(model_init.rho)\n",
    "# d.VPUPPERLIM = 3000.\n",
    "# d.VSUPPERLIM = 2500.\n",
    "# d.RHOUPPERLIM = 2500.\n",
    "d.VPUPPERLIM =np.max(model_init.vp)+1000\n",
    "d.VSUPPERLIM = np.max(model_init.vs)+500\n",
    "d.RHOUPPERLIM = np.max(model_init.rho)+500\n",
    "d.SWS_TAPER_FILE = 1\n",
    "taper = np.zeros_like(model_init.vp)\n",
    "print(taper.shape,wb_taper.shape)\n",
    "shift = 8\n",
    "taper[shift:, :] = wb_taper[:-shift,:] # water mask\n",
    "plt.imshow(taper)\n",
    "if d.SWS_TAPER_FILE:\n",
    "    os.makedirs(d._root_tapers, exist_ok=True)\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper.bin'))\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper_u.bin'))\n",
    "    ld.write_bin(np.fliplr((1 - taper.astype(np.float32).T)), os.path.join(d._root_tapers, 'taper_rho.bin'))\n",
    "    vis.plot_acquisition(taper, dx, src, rec)\n",
    "\n",
    "d.fwi_stages=[]\n",
    "####################################### cnn_input_fwi_strategy  #########################################################\n",
    "d.STEPMAX=200\n",
    "################### gradient step length estimation\n",
    "##########  testshots for gradient step length estimation,    (TESTSHOT_START,TESTSHOT_END,TESTSHOT_INCR) = 1,17,2\n",
    "d.TESTSHOT_START=1; d.TESTSHOT_END=len(src._ones);  d.TESTSHOT_INCR=5\n",
    "d.EPS_SCALE=0.0001\n",
    "d.SCALEFAC=1.2\n",
    "################### seismic data bandwidth\n",
    "TIME_FILT=1\n",
    "d.ITERMAX=ITERMAX\n",
    "################### define fwi stages\n",
    "########### make strong smoothing on low frequency data. [0,6] hz data\n",
    "freq=8; wd_damp=0\n",
    "d.add_fwi_stage(fc_low=0.0,fc_high=freq,time_filt=TIME_FILT,normalize=2,\n",
    "    e_precond=0,spatfilter=0,pro=1e-2,\n",
    "    wd_damp=wd_damp,wd_damp1=wd_damp)\n",
    "freq=10; wd_damp=0\n",
    "d.add_fwi_stage(fc_low=0.0,fc_high=freq,time_filt=TIME_FILT,normalize=2,\n",
    "    e_precond=0,spatfilter=0,pro=1e-5,\n",
    "    wd_damp=wd_damp,wd_damp1=wd_damp)\n",
    "for i,stage in enumerate(d.fwi_stages):\n",
    "    print(f'Stage {i+1}:\\n\\t{stage}\\n')\n",
    "\n",
    "d.DATA_DIR =os.path.join(d.save_folder,'su','seis')\n",
    "# nodes number=10\n",
    "print(model.vp.shape)\n",
    "d.WRITE_STF = 0\n",
    "d.NPROCX = 4\n",
    "d.NPROCY = 2\n",
    "d.verbose = 0\n",
    "par_fwi_runtime = {'run_command': 'mpirun -np 32', 'disable': True}\n",
    "if d.DT is None:\n",
    "    d.DT = 0.002\n",
    "d.filename=os.path.join(d.save_folder,'seis_inversion.inp');    print(d.filename)\n",
    "d.MFILE=os.path.join(d.save_folder,'start/model')\n",
    "d.fwi(model_init, src, rec, **par_fwi_runtime)\n",
    "d.MFILE=os.path.join(d.save_folder,'start/model_init')\n",
    "d.fwi(model_init, src, rec, **par_fwi_runtime)\n",
    "copy_su_from_to('./out_for_pasha/su/field',os.path.join(d.save_folder,'su'))\n",
    "denise_folder_process('crop_zero_freqs',results_path,denise_root=denise_root)\n",
    "denise_folder_process('plot',results_path,denise_root=denise_root)\n",
    "\n",
    "# api._cmd('rm -r '+os.path.join(d.save_folder,'su'))\n",
    "# copy_su_from_to('./out_for_pasha/su/field',os.path.join(d.save_folder,'su'))\n",
    "# denise_folder_process('crop_zero_freqs',results_path,denise_root=denise_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inversion to generate CNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = 'import sys,os\\n'\n",
    "imports = imports+f\"sys.path.append(os.getcwd())\\n\"\n",
    "imports = imports+f\"sys.path.append('/lustre/project/k1404/pavel/DENISE-Black-Edition')\\n\"\n",
    "imports = imports+'from F_utils import *\\n'\n",
    "imports = imports+'from F_plotting import *\\n'\n",
    "imports = imports+'from F_fwi import *\\n'\n",
    "imports = imports+'import fnmatch\\n'\n",
    "imports = imports+'from glob import glob\\n'\n",
    "imports = imports+'import numpy as np\\n'\n",
    "imports = imports+'import pyapi_denise_pavel as api\\n'\n",
    "post_processing = imports\n",
    "post_processing = post_processing+f\"denise_folder_process('plot','{results_path}',denise_root='{denise_shaheen_root}')\\n\"\n",
    "# post_processing = post_processing+f\"denise_folder_process('optimizing_space_','{results_path}',denise_root='{denise_shaheen_root}')\\n\"\n",
    "# post_processing = post_processing+f\"denise_folder_process('plot','{results_path}',denise_root='{denise_shaheen_root}')\\n\"\n",
    "post_processing_script_name = os.path.join(results_path,'post_processing_script.py')\n",
    "print(post_processing_script_name)\n",
    "f = open(post_processing_script_name,'w');  f.write(post_processing);   f.close()\n",
    "create_sbatch_file_for_fwi_folder('cnn.sh',results_path)\n",
    "print('scp -r plotnips@10.68.138.162:/home/plotnips/Dropbox/Log_extrapolation/scripts/DENISE-Black-Edition-master/for_pasha/out_for_pasha/cnn /lustre/project/k1404/pavel/DENISE-Black-Edition/for_pasha/out_for_pasha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inversion on full-frequency range with proofed to work strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted model\n",
    "The code ouputs inverted models for every elastic property at every FWI stage. Change `vp` to `vs` or `rho` to explore respective outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.set_model(model_init)\n",
    "# print(d.save_folder)\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "d.verbose = 2\n",
    "\n",
    "models, fnames = d.get_fwi_models(['vp', 'stage'], return_filenames=True)\n",
    "for m, f in zip(models, fnames):\n",
    "    vis.plot_log_model(m, dx, nx0, nz0, src, log=wlog, log_location=log_location, **limits_vp)\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-logs\n",
    "Plot logs in true model (dashed) and inverted models (solid) for every inversion stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inverted models from all stages\n",
    "vvr = {'vp': None, 'vs': None, 'rho': None}\n",
    "for k in vvr.keys():\n",
    "    vvr[k], fnames = d.get_fwi_models([k + '_stage'], return_filenames=True)\n",
    "\n",
    "for i in range(len(vvr['vp'])):\n",
    "    plot_logs(model_log, api.Model(vvr['vp'][i], vvr['vs'][i], vvr['rho'][i], dx), log_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.verbose = 0\n",
    "grads, fnames = d.get_fwi_gradients(return_filenames=True)\n",
    "for g, f in zip(grads, fnames):\n",
    "    plot_model(g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_last():\n",
    "    all_fnames = []\n",
    "    # vps, fnames = d.get_fwi_models(['vp', 'stage'], return_filenames=True)\n",
    "    vps, fnames = d.get_fwi_models(['vp'], return_filenames=True)\n",
    "    all_fnames += fnames\n",
    "    vss, fnames = d.get_fwi_models(['vs'], return_filenames=True)\n",
    "    all_fnames += fnames\n",
    "    rhos, fnames = d.get_fwi_models(['rho'], return_filenames=True)\n",
    "    all_fnames += fnames\n",
    "    print(all_fnames)\n",
    "    if all_fnames:\n",
    "        for f in all_fnames:\n",
    "            if not f.split('/')[-1] in os.listdir(f'{root_fwi}start/'):\n",
    "                command = f'cp {f} {root_fwi}start/'\n",
    "                print(command)\n",
    "                os.system(command)\n",
    "    if vps:\n",
    "        print(f'Init new starting model from {fnames[-1]}')\n",
    "        model_last = api.Model(vps[-1], vss[-1], rhos[-1], dx)\n",
    "    # print(vps)\n",
    "    return model_last\n",
    "    # return None\n",
    "model_last=get_model_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_model(model_last.vp / 1000, **limits_vp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare wavefiedls before/after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vps, fnames = d.get_fwi_models(['vp_stage'], return_filenames=True)\n",
    "vss, fnames = d.get_fwi_models(['vs_stage'], return_filenames=True)\n",
    "rhos, fnames = d.get_fwi_models(['rho_stage'], return_filenames=True)\n",
    "print(d.save_folder)\n",
    "if vps:\n",
    "    model_last = api.Model(vps[-1], vss[-1], rhos[-1], dx)\n",
    "    print(f'Found last model at {fnames[-1]}')\n",
    "else:\n",
    "    print(f'Not found the inverted model in {d.save_folder}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.save_folder = root_fwi[:-1] + '_wavefield/'\n",
    "print(f'{root_fwi[:-1]} --> {d.save_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_forward = {'run_command': 'mpirun -np 39', 'disable': False}\n",
    "par_forward = {'run_command': 'mpirun -np 39', 'disable': True}\n",
    "print(par_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.NPROCX = 1\n",
    "d.NPROCY = 1\n",
    "d.forward(model_last, src, rec, **par_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src.x[19], src.x[62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d.verbose = 0    # don't show redundant print outs\n",
    "\n",
    "if d.DT is None:\n",
    "    d.DT = 0.002\n",
    "shots = d.get_shots(keys=['_p'])\n",
    "# shots = [ld.bandpass(s, fs=1./(d.DT * d.NDT), **par_bp) for s in d.get_shots(keys=['_p'])]\n",
    "print(f'Read {len(shots)} shots {shots[0].shape} into list')\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "# for ishot in [int(np.floor(x)) for x in np.linspace(0, len(shots)-1, 5)]:\n",
    "for ishot in [19, 62]:\n",
    "    print(ishot)\n",
    "    shot_s = divmax(shots[ishot])\n",
    "    shot_f = divmax(data_p[ishot, :, ::d.NDT])\n",
    "#     vis.plot_shot(np.concatenate([np.flip(shot_s, 0), shot_f], axis=0), pclip=0.05)\n",
    "    vis.plot_compare_stripes(shot_s, shot_f, pclip=0.0125, colorbar=False, dt=d.DT, dx=dx)\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f46140b79a25c3b1ec622d9de359221a8d5802b8a7ad490aae66b50110296176"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
